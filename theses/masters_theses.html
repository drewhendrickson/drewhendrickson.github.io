<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Masters Theses</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width">

    <link rel="stylesheet" href="css/style.css">

  <link rel="icon" type="image/png" href="ccs-favicon.png">

  </head>
  <body>

    <h3>Masters Students</h3>

    <ul>
      <li>Laura Kooijman (Fall 2020) <a href="Laura_Kooijman_thesis_F2020.pdf">pdf</a>
      <p><em>Abstract:</em> In professional cycling training schedules are optimized to perfection. But to know on beforehand
if the training schedule has the desired effect, there is the need to know what effect the training
had on race performance. In this research a logistic regression, a support vector machine and a
random forest are developed to predict race performance of a professional female cyclist, based on
training load. The data consists of the races and training of 2017-2019. The research question
that will be answered is: To what extent can race performance be predicted in cycling, based on
        training load?</p>
<p>Athlete data is often limited in size as athletes only can do a number of races per year which
makes the data impractical for predictive modelling. This study investigates which techniques are
helpful in classifying race performance. Class balancing is performed using weight adjustment
and the SMOTE technique. In addition to that, PCA is performed. The random forest with
weight adjustment gave the best result with a F1-score of 0.88, which shows that it is possible to
predict race performance with a small dataset. The PCA showed an improvement in prediction
for the SVM with an F1-score of 0.872, which is an improvement but not as high as the random
forest. This means that the PCA was not beneficial for this dataset.</p></li>
      
      <li>Loes Modderman (Fall 2020) <a href="Loes_Modderman_thesis_F2020.pdf">pdf</a>
      <p><em>Abstract:</em> Amusement parks deal with crowdedness and managing this crowd almost every day.
This crowdedness may cause waiting times in general to get higher which in turn may cause
dissatisfied guests (Furnham, Treglown, and Horne 2020). The research field of managing flow
and capacity in amusement parks has been studying for several years how to control the crowds
using several methods mostly by running simulations (Ahmadi 1997; Cheng et al. 2013; Zhang,
Li, and Su 2017; Yuan and Zheng 2018). This study researches the effect of three different
crowd management methods on the waiting time of attractions and the crowd distribution in
amusement park the Efteling. The three methods are the placement of physical signing across the
park, the sending out of push notifications containing information and tips about crowdedness,
and a recommendation app for a phone to recommend attractions and restaurants. This research
will analyse these effects using data collected from real life. The data that is used for this study is
provided by amusement park the Efteling. The results show that none of the crowd management
methods have an effect on the waiting times nor the crowd distribution. However, these results
may be inaccurate and can be improved by further optimising the prediction models that are
used to compute the results.</p></li>
      
      <li>Jeroen Simonse (Fall 2020) <a href="Jeroen_Simonse_thesis_F2020.pdf">pdf</a>
      <p><em>Abstract:</em> With the already 30000 unique game titles that are available on the Steam platform, and
developers releasing more games every year, the average gamer might be overwhelmed by the
abundance of game titles. To make sure the users of the platform don’t get lost in the game store,
there are systems working on the background, that make sure the users only gets to see relevant
games. These systems are called recommender systems, and they try to recommend games to the
user, based on the users’ past interests. The two most popular methods for recommending items
to users, are the collaborative filtering method and the content based filtering method. This study
focuses on these two methods, and tries to determine which of the two methods provides the best
recommendations for the users of Steam. The data used for this study contained information
about the what games each user owned, how long each user played a game and the characteristics
of each game. First the collaborative model was constructed, which combines the individual
interests with the opinions of other users to predict recommendations. Then the content based
model was constructed, which focuses more on the contents and the characteristics of a game. The
results of this study showed that the collaborative filtering method was superior to the content
based method, which corresponds with the research that already has been conducted on this topic.
</p></li>
      
      <li>Mehmet Turgut (Fall 2020) <a href="Mehmet_Turgut_thesis_F2020.pdf">pdf</a>
      <p><em>Abstract:</em> For this thesis, the predictive performances of Machine Learning and Deep Learning methods
have been researched for predicting Mixed Martial Arts matches. The goal of this study was
to answer the research question What is the difference in the prediction performance that can
be achieved by DL models compared to traditional ML models by predicting MMA matches?
During this study, a Random Forest and an Artificial Neural Network were trained on data
        from the past 22 years. The data is made available by the Ultimate Fighting Championship.</p>
<p>Two data sets were scraped from www.ufcstats.com. These were then combined into a
single data set. During the feature engineering process, great emphasis was put on preventing
information leakage from occurring. Using random search algorithms for hyperparameter
tuning, the Random Forest and Neural Network were able to achieve test set accuracies of
58.98% and 59.11% respectively. These accuracies are in-line with the results of other similar
studies focusing on sports prediction. So it is hard to say if the sport of Mixed Martial Arts
  is more or less predictable compared to other sports that have commonly been researched.</p>
<p>However, information leakage is not always taken into account while building models for
sport prediction. An additional set of models were trained to find out what the effect would
be if no precautions were taken to prevent information leakage. The Random Forest and
Neural Network models with information leakage achieved test set accuracies of 65.11% and
        68.59% respectively.</p>
<p>The results of this thesis highlight the predictive performance of Random Forests and
Neural Networks with regards to Mixed Martial Arts predictions. In addition, the results
also highlight the effects of information leakage, not just in sports prediction, but in all
of Machine Learning. Insufficient measures to prevent information leakage can lead to too
optimistic results, which are not realistically achievable in real-life settings once a model is
deployed.</p></li>
      
      <li>Carien Dijkhof (Spring 2020) <a href="Carien_Dijkhof_thesis_S2020.pdf">pdf</a>
      <p><em>Abstract:</em> In a society where young adults comprehensively use smartphones and social media, the
effects of this usage are more being researched due to negative effects on well-being. This
study focuses on the influence of social media usage on mental tiredness and forecasting
        mental tiredness among young Dutch adults by using binary classification models.</p>
<p>Most research done regarding the effects of social media on the mental state are from a
social science or experimental origin. This research will try to predict mental tiredness based
on social media usage with the use of machine learning tools. With exploratory data analysis
  and feature selection tools, relevant features are selected for this classification problem.</p>
<p>Using classification algorithms Logistic Regression, K-nearest Neighbour, Random
Forest, and Support Vector Machines, this research will compare 4 main models with
different subsets of data and features. The algorithms are tested on data derived from two
  datasets containing phone use data and self-reported mood data.</p>
<p>The results show an inconsistent trend against the baseline. KNN and Logistic
Regression showed no clear improvement than the baseline. In general, Random Forest and
SVM performed better than the baseline approaches, with Random Forest showing on average
the best performance in terms of accuracy among the 4 different classification algorithms. The
  highest accuracy achieved was by SVM model.</p>
<p>The results provide new models for detecting mental tiredness among young Dutch
adults, which can be used in future research. For future research, adding additional
meaningful features to these models potentially improve the performance of the classification</p></li>
      
      <li>Andrea Favia (Spring 2020) <a href="Andrea_Favia_thesis_S2020.pdf">pdf</a>
      <p><em>Abstract:</em> Interpretability in models which deal with human language is a field rich in questions and potential, and cutting-edge research brings innovation to the tools used to understand how deep learning
models reach an interesting level of capability in the classification, prediction and generation of
language. The present thesis focuses on the processing of text data by means of two different
transformer models, a POS-Tagger and a Language Model (henceforth LM), to investigate whether
these go through similar learning phases when given the same data tagged on different levels of
abstraction (namely syntax and lexicon). The intuition is that the models will have to undergo a
similar learning process as the POS-Tagger one, since syntactic acquisition is a pre-requisite to the
acquisition of higher levels of language, which has been researched in the field of deep learning by
taking inspiration from language acquisition.</p>
<p>The models have been trained on the WikiText dataset, which is a widely employed dataset in
  language modeling and POS tagging tasks, often used for benchmarking models.</p>
<p>In order to investigate how the models learn, and whether they might follow similar learning
patterns, the SVCCA and CKA algorithms have been applied to measure and compare layers
similarity within and between the models, as well as the same layers across epochs during training.
A second goal of this thesis was to determine if the two methods yielded comparable results. These
algorithms have successfully allowed to find significant similarities between the first two layers of
the models, and also gain insights into the LM structure, suggesting that the two sets of layers
should share similar information and have learned similar features. Finally, the results of SVCCA
and CKA are shown, and a case is made on which algorithm may be more appropriate to use for
certain analyses.</p></li>
      
      <li>Ion Iuncu (Spring 2020) <a href="">pdf</a>
      <p><em>Abstract:</em> </p></li>
      
      <li>Joeri van de Rijdt (Spring 2020) <a href="Joeri_van_de_Rijdt_thesis_S2020.pdf">pdf</a>
      <p><em>Abstract:</em> The purpose of this study is to predict the correct social media usage class of individuals. The
basis for these classes is the duration that individuals spend on social media platforms.
Different machine learning algorithms are utilized to address this problem. The data at hand
consists of phone tracking data and mood survey data. The main question to be answered is to
what extent machine learning algorithms can predict these social media classes, using a
combination of the two mentioned data types. This problem as well as the combination of
phone and mood features have not been studied in literature before. The metrics to evaluate
the performance of the models are accuracy and recall. As it turns out, all models outperform
their benchmark when it comes to accuracy. With regard to recall, only some of the models
outperform their benchmark. Recall is a more important metric than accuracy to predict
problematic social media usage. Overall, the predictive value of the machine learning
algorithms is not large enough to have an impact on businesses. There are several
opportunities for future research.</p></li>
      
      <li>Marieke Roost (Spring 2020) <a href="Marieke_Roost_thesis_S2020.pdf">pdf</a>
      <p><em>Abstract:</em> People seem to use their smartphone more intensively every year. Excessive use of smartphones influences people’s mood, mental health, and
well-being in a negative way. This excessive use is becoming a big problem
as people are experiencing diculties because of this in daily life. Previous
research has studied the relationship between mood and smartphone use by
analyzing one or a few negative emotions. This present research uses a representational similarity analysis, a multivariate analysis method, to study
this relationship with a broader range of moods and smartphone behavior
features. The results of this research show weak correlations between similarity in smartphone use and similarity in mood in general with this analysis
method and data. Furthermore, a small di↵erence is found between positive
and negative moods for smartphone behavior. Also, this study shows that
the duration of smartphone use and the frequency of smartphone use are
both useful measures to explain smartphone use. The results suggest that
this present research might not provide enough information to state that
there is a strong relationship between smartphone use and mood using RSA
and this type of data.</p></li>
      
      <li>Maartje Verhoeven (Spring 2020) <a href="Maartje_Verhoeven_thesis_S2020.pdf">pdf</a>
      <p><em>Abstract:</em> Insight into how smartphone usage affects mood is important in order to enable people to use their
smartphones in a manner that improves rather than deteriorates their wellbeing as an increasing amount of
people is struggling with their smartphone usage. This study investigates the extent to which smartphone
application usage can predict mood among blocks of measurement in panel studies. Panel conditioning and
panel attrition have been widely discussed in the social sciences to affect the quality of the results but this
has, to our knowledge, never been taken into account for predictive models in the field of data science. Data
from a population of 124 first year Psychology students at Tilburg University, measured in period of 34
days, were used to train and tune several learning algorithms and compare models from different blocks of
measurements. Results indicate the Random Forest (RF) classifier to best predict mood from application
usage and the model containing data from the first half of the study to score highest in comparison to the
other defined models. However, the achieved accuracy scores were only slightly above the baseline and the
predictive performance is therefore considered to be low. It is recommended for future research to use more
frequent mood measurements as it was not possible to capture the experienced mood at the moment that
the smartphone was used with the limited measurements from this study.</p></li>
      
      
      <li>Catherine Schwitzer <a href="Catherine_Schweitzer_Thesis.pdf">pdf</a>
      <p><em>Abstract:</em> The goal of this research was to determine if clustering mobile phone data can be used to
segment users into groups based on their behavior. Previous studies have attempted to profile
users according to mobile phone behavior, but they pre-determined the qualities of the
profiles manually as opposed to clustering. Studies that did utilize clustering for mobile
phone analysis primarily focused on predicting the next app users would open. This research
uses logging data from the MobileDNA app from Ghent University to create standard phone
behavior features, as well as new ones that quantify notification response time. Principal
component analysis was conducted on the feature set before clustering using DBSCAN. The
clustering results assigned most users into one main clusters, which suggests that clustering
may not be the most appropriate method for user profiling and that users are better considered
with regard to a spectrum of behavior. Additionally, it found notification response time is an
important feature in differentiating users and should be included in future studies.</p></li>
      
      <li>Eefje de Louw <a href="Eefje_de_Louw_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This research examines the effect of Conversational Human Voice on User Experience in chatbots in the context
of survey research performed by the municipality of ’s-Hertogenbosch (The Netherlands). Literature of suggests
that Conversational Human Voice has a positive effect on User Experience, but that never has been tested.
Therefore, this study proposes the following first research question: What is the effect of Conversational Human
Voice on the User Experience? In the research of Human-Computer Interaction, it is known that humans are
likely to attribute human characteristics to the computer when they interact with them and show similarities to
Human-Human interaction. It is said that people tend to adapt their language use to that of their conversational
agent. Therefore, this study proposes the second research question: To what extent do users alter their language
use to the addition of elements of Conversational Human Voice of the chatbot? The results of 551 participants
were analysed and the following conclusions are drawn: Conversational Human Voice does not necessarily lead
to a higher User Experience score in the context of survey research. For the context of survey research, one can
rather stick to the functional communication styles. Compared to the other Conversational Human Voice
categories, inviting rhetoric seems most suitable in the context of survey research. Significant differences were
found for the “helpfulness” and “clearness” of the chatbots. All in all, chatbots do show potential, but mainly in
more bound contexts such as answering frequently asked questions or managing appointment.</p></li>
      
      <li>Ronny Brouwers <a href="Ronny_Brouwers_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This thesis project used experimental, cross-situational, word-learning data, and the correct combination
of pseudo words and novel objects had to be identified in an ambiguous setting.
The first research question of this project aimed to identify which individual features could be used to
predict whether subjects would learn a word pair correctly in the testing phase. Based on the literature,
five potential features were identified and tested using a logistic regression and random forest algorithm.
The results showed that the more frequently a word-object
pair was presented without uncertainty, the more likely the pair was to be learned correctly.
The second research question focused on identifying different types of learners, as the literature showed
that different subjects may learn differently.
A Gaussian mixture model and hierarchical clustering were used, and clustering
analysis showed that the identified clusters were poorly separated and contained much noise.</p></li>
      
      <li>Yashi Thakkar <a href="Yashi_Thakkar_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This thesis aims at predicting an image based on different texts describing that image and question asked
while guessing the image.
The main research question is to evaluate the self-sufficiency of text data to identify a portrait with the help of text mining and similarity measures.
We used two types of vector space model combined with two types of decision rules and one similarity measure that is cosine similarity.
In our research, term frequency and inverse document frequency performed the best with a precision of 49%.
This shows how text itself can help reduce number of alternatives at the time of decision making. This
seems very useful in the area where tasks related to finding suspects are concerned.
Moreover, retaining few parts of speech can be helpful to increase the speed of mining as they retain a lot
of information simultaneously reducing the noise. </p></li>
      
      <li>Zeynep Oncu <a href="Zeynep_Oncu_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This study is a comparative analysis of supervised learning tasks using categorical texts and free-text
questions about facial details of people. The datasets used for this research were collected through online
experiments. This study used pre-trained word representations, which are known to be perform better than
the traditional text mining approaches. Categorical texts and word embeddings of question texts were
used as features in classification algorithms and their performances were evaluated with accuracy rates in
predicting answers to the questions. In other words, the research question was formed as “Which pretrained word embedding and classification models perform best in terms of accuracy rate in predicting
answers to yes/no questions?”
The findings showed that use of pre-trained word embedding models indeed led to better predictive
performances in some classification algorithms compared to the baseline for this dataset. </p></li>
      
      <li>Maarten Jansen <a href="Maarten_Jansen_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This work investigates culture and cultural influence of visual narrative structures in
comic books, using a machine learning approach. It is motivated by proof that comics
are susceptible to adjustments stimulated by culture, and the scarcity of a machine
learning approach in studies on comics. Our main contribution is a better
understanding concerning cross-cultural differences in visual language, and evolvement
over time from a novel perspective. We find this contribution by asking the following
research question: To what extent can we predict continent, country, and decade of
publication based on narrative patterns in comic books published in the last eight
decades? The answer to this question is obtained by training a decision tree and naive
Bayes classifier, using narrative patterns extracted from the Visual Language Research
Corpus. The results demonstrate that there are cultural distinctions in patterns if we
examine continent or country of publication. However, if we examine decade of
publication we witness fewer characteristics pointing towards changes over time, unless
the time period investigated is of sufficient length, for example 50 years.</p></li>
    </ul>

  </body>
</html>
