<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Masters Theses</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width">

    <link rel="stylesheet" href="css/style.css">

  <link rel="icon" type="image/png" href="ccs-favicon.png">

  </head>
  <body>

    <h3>Masters Students</h3>

    <ul>

      <li>Barbora Pisecka (Fall 2022) <a href="F2022_Barbora_Pisecka_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Pieter van Brakel (Fall 2022) <a href="F2022_Pieter_van_Brakel_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Sarina Kasiemkhan (Fall 2022) <a href="F2022_Sarina_Kasiemkhan_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Kiki Peeters (Fall 2022) <a href="F2022_Kiki_Peeters_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Agata Rapiej (Fall 2022) <a href="F2022_Agata_Rapiej_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Rowanne Trapmann (Fall 2022) <a href="F2022_Rowanne_Trapmann_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>

      <li>Noor Meijer (Spring 2022) <a href="S2022_Noor_Meijer_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Bidus Plomp (Spring 2022) <a href="S2022_Bidus_Plomp_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Katharina Pritzl (Spring 2022) <a href="S2022_Katharina_Pritzl_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Thomas Willekes (Spring 2022) <a href="S2022_Thomas_Willekes_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      
      

      <li>Robin van Heesch (Fall 2021) <a href="F2021_Robin_van_Heesch_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Tessa Roes (Fall 2021) <a href="F2021_Tessa_Roes_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Floris Zanders (Fall 2021) <a href="F2021_Floris_Zanders_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      
      
      <li>Lotte van der Klei (Spring 2021) <a href="S2021_Lotte_van_der_Klei_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Sjors van den Boomen (Spring 2021) <a href="S2021_Sjors_van_den_Boomen_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Ramya Ramachandran (Spring 2021) <a href="S2021_Ramya_Ramachandran_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>
      <li>Stephan Krijger (Spring 2021) <a href="S2021_Stephan_Krijger_thesis.pdf">pdf</a>
          <p><em>Abstract:</em> </p>
      </li>


      <li>Laura Kooijman (Fall 2020) <a href="F2020_Laura_Kooijman_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> In professional cycling training schedules are optimized to perfection. But to know on beforehand
if the training schedule has the desired effect, there is the need to know what effect the training
had on race performance. In this research a logistic regression, a support vector machine and a
random forest are developed to predict race performance of a professional female cyclist, based on
training load. The data consists of the races and training of 2017-2019. The research question
that will be answered is: To what extent can race performance be predicted in cycling, based on
        training load?</p>
<p>Athlete data is often limited in size as athletes only can do a number of races per year which
makes the data impractical for predictive modelling. This study investigates which techniques are
helpful in classifying race performance. Class balancing is performed using weight adjustment
and the SMOTE technique. In addition to that, PCA is performed. The random forest with
weight adjustment gave the best result with a F1-score of 0.88, which shows that it is possible to
predict race performance with a small dataset. The PCA showed an improvement in prediction
for the SVM with an F1-score of 0.872, which is an improvement but not as high as the random
forest. This means that the PCA was not beneficial for this dataset.</p></li>
      
      <li>Loes Modderman (Fall 2020) <a href="F2020_Loes_Modderman_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> Amusement parks deal with crowdedness and managing this crowd almost every day.
This crowdedness may cause waiting times in general to get higher which in turn may cause
dissatisfied guests (Furnham, Treglown, and Horne 2020). The research field of managing flow
and capacity in amusement parks has been studying for several years how to control the crowds
using several methods mostly by running simulations (Ahmadi 1997; Cheng et al. 2013; Zhang,
Li, and Su 2017; Yuan and Zheng 2018). This study researches the effect of three different
crowd management methods on the waiting time of attractions and the crowd distribution in
amusement park the Efteling. The three methods are the placement of physical signing across the
park, the sending out of push notifications containing information and tips about crowdedness,
and a recommendation app for a phone to recommend attractions and restaurants. This research
will analyse these effects using data collected from real life. The data that is used for this study is
provided by amusement park the Efteling. The results show that none of the crowd management
methods have an effect on the waiting times nor the crowd distribution. However, these results
may be inaccurate and can be improved by further optimising the prediction models that are
used to compute the results.</p></li>
      
      <li>Jeroen Simonse (Fall 2020) <a href="F2020_Jeroen_Simonse_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> With the already 30000 unique game titles that are available on the Steam platform, and
developers releasing more games every year, the average gamer might be overwhelmed by the
abundance of game titles. To make sure the users of the platform don’t get lost in the game store,
there are systems working on the background, that make sure the users only gets to see relevant
games. These systems are called recommender systems, and they try to recommend games to the
user, based on the users’ past interests. The two most popular methods for recommending items
to users, are the collaborative filtering method and the content based filtering method. This study
focuses on these two methods, and tries to determine which of the two methods provides the best
recommendations for the users of Steam. The data used for this study contained information
about the what games each user owned, how long each user played a game and the characteristics
of each game. First the collaborative model was constructed, which combines the individual
interests with the opinions of other users to predict recommendations. Then the content based
model was constructed, which focuses more on the contents and the characteristics of a game. The
results of this study showed that the collaborative filtering method was superior to the content
based method, which corresponds with the research that already has been conducted on this topic.
</p></li>
      
      <li>Mehmet Turgut (Fall 2020) <a href="F2020_Mehmet_Turgut_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> For this thesis, the predictive performances of Machine Learning and Deep Learning methods
have been researched for predicting Mixed Martial Arts matches. The goal of this study was
to answer the research question What is the difference in the prediction performance that can
be achieved by DL models compared to traditional ML models by predicting MMA matches?
During this study, a Random Forest and an Artificial Neural Network were trained on data
        from the past 22 years. The data is made available by the Ultimate Fighting Championship.</p>
<p>Two data sets were scraped from www.ufcstats.com. These were then combined into a
single data set. During the feature engineering process, great emphasis was put on preventing
information leakage from occurring. Using random search algorithms for hyperparameter
tuning, the Random Forest and Neural Network were able to achieve test set accuracies of
58.98% and 59.11% respectively. These accuracies are in-line with the results of other similar
studies focusing on sports prediction. So it is hard to say if the sport of Mixed Martial Arts
  is more or less predictable compared to other sports that have commonly been researched.</p>
<p>However, information leakage is not always taken into account while building models for
sport prediction. An additional set of models were trained to find out what the effect would
be if no precautions were taken to prevent information leakage. The Random Forest and
Neural Network models with information leakage achieved test set accuracies of 65.11% and
        68.59% respectively.</p>
<p>The results of this thesis highlight the predictive performance of Random Forests and
Neural Networks with regards to Mixed Martial Arts predictions. In addition, the results
also highlight the effects of information leakage, not just in sports prediction, but in all
of Machine Learning. Insufficient measures to prevent information leakage can lead to too
optimistic results, which are not realistically achievable in real-life settings once a model is
deployed.</p></li>
      
      <li>Carien Dijkhof (Spring 2020) <a href="S2020_Carien_Dijkhof_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> In a society where young adults comprehensively use smartphones and social media, the
effects of this usage are more being researched due to negative effects on well-being. This
study focuses on the influence of social media usage on mental tiredness and forecasting
        mental tiredness among young Dutch adults by using binary classification models.</p>
<p>Most research done regarding the effects of social media on the mental state are from a
social science or experimental origin. This research will try to predict mental tiredness based
on social media usage with the use of machine learning tools. With exploratory data analysis
  and feature selection tools, relevant features are selected for this classification problem.</p>
<p>Using classification algorithms Logistic Regression, K-nearest Neighbour, Random
Forest, and Support Vector Machines, this research will compare 4 main models with
different subsets of data and features. The algorithms are tested on data derived from two
  datasets containing phone use data and self-reported mood data.</p>
<p>The results show an inconsistent trend against the baseline. KNN and Logistic
Regression showed no clear improvement than the baseline. In general, Random Forest and
SVM performed better than the baseline approaches, with Random Forest showing on average
the best performance in terms of accuracy among the 4 different classification algorithms. The
  highest accuracy achieved was by SVM model.</p>
<p>The results provide new models for detecting mental tiredness among young Dutch
adults, which can be used in future research. For future research, adding additional
meaningful features to these models potentially improve the performance of the classification</p></li>
      
      <li>Andrea Favia (Spring 2020) <a href="S2020_Andrea_Favia_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> Interpretability in models which deal with human language is a field rich in questions and potential, and cutting-edge research brings innovation to the tools used to understand how deep learning
models reach an interesting level of capability in the classification, prediction and generation of
language. The present thesis focuses on the processing of text data by means of two different
transformer models, a POS-Tagger and a Language Model (henceforth LM), to investigate whether
these go through similar learning phases when given the same data tagged on different levels of
abstraction (namely syntax and lexicon). The intuition is that the models will have to undergo a
similar learning process as the POS-Tagger one, since syntactic acquisition is a pre-requisite to the
acquisition of higher levels of language, which has been researched in the field of deep learning by
taking inspiration from language acquisition.</p>
<p>The models have been trained on the WikiText dataset, which is a widely employed dataset in
  language modeling and POS tagging tasks, often used for benchmarking models.</p>
<p>In order to investigate how the models learn, and whether they might follow similar learning
patterns, the SVCCA and CKA algorithms have been applied to measure and compare layers
similarity within and between the models, as well as the same layers across epochs during training.
A second goal of this thesis was to determine if the two methods yielded comparable results. These
algorithms have successfully allowed to find significant similarities between the first two layers of
the models, and also gain insights into the LM structure, suggesting that the two sets of layers
should share similar information and have learned similar features. Finally, the results of SVCCA
and CKA are shown, and a case is made on which algorithm may be more appropriate to use for
certain analyses.</p></li>
      
      <li>Ion Iuncu (Spring 2020) <a href="">pdf</a>
      <p><em>Abstract:</em> </p></li>
      
      <li>Joeri van de Rijdt (Spring 2020) <a href="S2020_Joeri_van_de_Rijdt_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> The purpose of this study is to predict the correct social media usage class of individuals. The
basis for these classes is the duration that individuals spend on social media platforms.
Different machine learning algorithms are utilized to address this problem. The data at hand
consists of phone tracking data and mood survey data. The main question to be answered is to
what extent machine learning algorithms can predict these social media classes, using a
combination of the two mentioned data types. This problem as well as the combination of
phone and mood features have not been studied in literature before. The metrics to evaluate
the performance of the models are accuracy and recall. As it turns out, all models outperform
their benchmark when it comes to accuracy. With regard to recall, only some of the models
outperform their benchmark. Recall is a more important metric than accuracy to predict
problematic social media usage. Overall, the predictive value of the machine learning
algorithms is not large enough to have an impact on businesses. There are several
opportunities for future research.</p></li>
      
      <li>Marieke Roost (Spring 2020) <a href="S2020_Marieke_Roost_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> People seem to use their smartphone more intensively every year. Excessive use of smartphones influences people’s mood, mental health, and
well-being in a negative way. This excessive use is becoming a big problem
as people are experiencing diculties because of this in daily life. Previous
research has studied the relationship between mood and smartphone use by
analyzing one or a few negative emotions. This present research uses a representational similarity analysis, a multivariate analysis method, to study
this relationship with a broader range of moods and smartphone behavior
features. The results of this research show weak correlations between similarity in smartphone use and similarity in mood in general with this analysis
method and data. Furthermore, a small di↵erence is found between positive
and negative moods for smartphone behavior. Also, this study shows that
the duration of smartphone use and the frequency of smartphone use are
both useful measures to explain smartphone use. The results suggest that
this present research might not provide enough information to state that
there is a strong relationship between smartphone use and mood using RSA
and this type of data.</p></li>
      
      <li>Maartje Verhoeven (Spring 2020) <a href="S2020_Maartje_Verhoeven_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> Insight into how smartphone usage affects mood is important in order to enable people to use their
smartphones in a manner that improves rather than deteriorates their wellbeing as an increasing amount of
people is struggling with their smartphone usage. This study investigates the extent to which smartphone
application usage can predict mood among blocks of measurement in panel studies. Panel conditioning and
panel attrition have been widely discussed in the social sciences to affect the quality of the results but this
has, to our knowledge, never been taken into account for predictive models in the field of data science. Data
from a population of 124 first year Psychology students at Tilburg University, measured in period of 34
days, were used to train and tune several learning algorithms and compare models from different blocks of
measurements. Results indicate the Random Forest (RF) classifier to best predict mood from application
usage and the model containing data from the first half of the study to score highest in comparison to the
other defined models. However, the achieved accuracy scores were only slightly above the baseline and the
predictive performance is therefore considered to be low. It is recommended for future research to use more
frequent mood measurements as it was not possible to capture the experienced mood at the moment that
the smartphone was used with the limited measurements from this study.</p></li>
      

      
      
      <li>Fenna Bronwasser (Fall 2019) <a href="F2019_Fenna_Bronwasser_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> Typographic errors, although being minor incidence, can influence the writing process by breaking the linear
writing flow. Classifying typographic revisions could function as a first step towards further analysis on
reducing the undesired effects of typographic errors, or for the purpose of filtering typographic revision; as
typographic errors are non-deliberate, mechanical errors which you might not want to include when analyzing other types of revisions. This study is a continuation of the research of Conijn, Zaanen, van Leijten, &
Van Waes, 2019. Whereas previous studies on typographic/typing errors focused mainly on the finished
writing product, this study utilizes a process-based approach which allows for the exploration of new features. In contrast to the research of Conijn et. al., (2019), this research focusses on typographic revision
instead of typographic errors, trains the model on writing tasks which have a more natural setting, compares
the typographic revision classification between first language writers and second language writers, and uses
fluency-based features for building a classification model. Results show that the fluency-based model was
reasonably effective in classifying typographic revision. A difference in performance of the model between
first and second languages writers was found, however it is unclear whether the dissimilarity in language
and language acquaintance accounts for this performance difference.
</p></li>
      
      <li>Gary van Koeverden (Fall 2019) <a href="F2019_Gary_van_Koeverden_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> Stress has a growing effect on society, predicting stress through smartphone usage seems a costeffective and convenient method to measure stress. This study investigates the influence of
different phone usage features on perceived stress levels and tests if these features can identify
perceived stress levels. Five different models are tested, both user-specific and generic models.
Three different classification algorithms were developed: Random Forest, Support Vector
Machine and k-Nearest Neighbours. The data consisted of two different sets, one dataset that
consisted of returned mental health surveys from a group of respondents and the other dataset
was the phone usage log data of the same group. This data was merged and the aim of this
study was to predict stress from small time frames of maximum two hours of phone usage data
upon every returned survey. First an exploratory analysis was done on the different models to
test which features have the strongest relation with the target stress levels. Afterwards the five
models were tested with the classification algorithms. The classification results indicate that
the classification algorithms do not perform better on the user-specific models as predictor for
stress than on generic models. The different classification algorithms and models show very
dissimilar results and predict in general not better than the baseline</p></li>
      
      <li>Bram de Kroon (Fall 2019) <a href="F2019_Bram_de_Kroon_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> Mobile phone technologies have developed rapidly over the past few years. To be able to facilitate
these continuously developing technologies, smartphones demand increasingly more battery
capacity. Improving smartphone energy efficiency is an ongoing challenge and is being addressed
from numerous perspectives. On another note, there is increasing interest in understanding how
smartphone users use their phone. This work is an initial attempt to determine how smartphone
users adapt their phone usage behavior to the battery level of their phone. Answers to this matter
might prove to be relevant for research regarding smartphone energy efficiency as well as the
understanding of smartphone usage itself. Six features have been evaluated which all represented a
concept of phone usage behavior and quantified to what extent a smartphone user adapts the
respective concept of phone usage behavior given two intervals of battery level. Results suggest
that distinct patterns of change in phone usage behavior cannot be accurately captured using
global intervals of battery level. Instead, they suggest that we should look closely to how
smartphone users adapt their phone usage behavior to a more continuous scale of battery level. </p></li>
      
      <li>Siyou Liu (Fall 2019) <a href="F2019_Siyou_Liu_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> The goal of this research is to examine what method can be used to transform the Likert scores of
different emotions into one emotional state indicator, and how accurately can Random Forest
Classifier be used to classify people’s emotional state based on their app usage behavior and app
category. The research question is: How accurately can people’s negative emotional state be
classified by their app usage behavior and app category? Whilst much previous research
investigated the association between people’s phone usage and emotion, this research sets out to
examine the joint effect of app usage like duration, frequency, earliest usage time. etc., together
with six different types of app categories, which provides deeper insights into the app usage
behavior. The app usage dataset used in this research was generated by software, which is more
reliable compared to self-reported app usage activities manually filled in by the users. Prior to
the classification, this research also used a dataset that contains eight different negative scores,
measured on a five-point Likert scale, to create the target variable. To be able to classify
emotional state instead of discrete emotion, the Likert scores of these eight variables were
transformed into one emotional indicator using k-means clustering and principal component
analysis, and resampling method as well as feature selection technique based on feature
importance was used for further improving the model accuracy. By the end of the research, an
accuracy of 90% was achieved.</p></li>
      

      <li>Emma Janssen (Fall 2019) <a href="F2019_Emma_Janssen_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> There has been considerable interest in the recognition of activities in day-to-day tasks.
The coordination of movements and gaze play an important role in this process. With the
development of wearable cameras, eye movements can be analysed from egocentric view
when performing activities of daily life (ADL). More research on this subject could result
in more knowledge on activity recognition which could contribute to research in the
practical field (healthcare). This study aims to predict to what extent an activity is
performed in ADLs, based on eye movements from egocentric view. This is done by the
annotation and analysis of wearable videos from six participants while performing the
activity of tea-making, which consisted of several smaller actions (e.g. pouring water,
finding cup etc.). The Random Forest technique was used in order to find an answer to
our research question. Analysis showed that there were no major differences in
performance between models. However, the models performed better than the majority
baseline score. It could be concluded that the models used in this study add value in
predicting activities. In addition, analysis of the performance of actions separately was
conducted. Analysis showed a difference between in the predictability of actions.</p></li>
      
      <li>Roderick Korthals (Fall 2019) <a href="F2019_Roderick_Korthals_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> The main goal of this study is to examine to what extent daily stress and anxiety levels can
be predicted by analyzing smartphone usage data. In the literature, it became clear that
smartphone use is linked to stress and anxiety, and predictive modeling has shown the
potential to utilize smartphone data to successfully predict mood. Therefore, a generic and
group-personalized model has been used to perform prediction tasks 1 and 2. The first
prediction task examined to what extent daily stress and anxiety levels of smartphone users
can be predicted by analyzing smartphone usage data. The second prediction task examined
to what extent daily stress and anxiety levels can be predicted by analyzing smartphone
usage data and the context when using a smartphone. Three machine learning algorithms
were applied, namely decision tree, logistic regression, a support vector machine, and
random forest. Overall, the models performed poorly for predicting stress and anxiety, and
the results showed that the models performed better for predicting anxiety than stress. The
random forest was the only model that had a moderate performance in the generic and
group-personalized model. Adding external factors improved the prediction performance of
the models. Moreover, the group-personalized model did improve the prediction task. The
percentage of notifications and the number of sessions were the most important features in
the generic model to predict anxiety. There were no crucial features identified in the generic
model to predict stress. Finally, in the group-personalized models, the daily use of other (not
defined) applications was of most importance when predicting stress. Daily use of Social
Media, daily use of other applications, and daily use of messaging apps were the most
important features to predict anxiety, although their value was limited. Since this research
showed that group-personalized models had limited value in the prediction task, further
research should use personalized models to predict mood. Besides, neural networks could
be used, which seem to be more suitable to the prediction task.</p></li>
      
      <li>Marlijn Y. Moonen (Fall 2019) <a href="F2019_Marlijn_Moonen_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> The main goal of this study was to evaluate conventional classification algorithms at predicting a
mobile phone users’ energy level by their phone activities. Before evaluating the classifiers on the
data, this study aimed to examine whether the predefined target variable ‘energy level’, which
consisted of six classes, was constructed in a reliable way. Subsequently we found that there were no
significant differences between some classes, hence the original six classes were merged into four
significantly different classes. As the reordered target variable has four classes, this study is
concerned with a multi-class classification problem. Additionally, the target variable is merged into
two classes, thereby making it a binary target variable. As such we were able to evaluate the
classifiers on both multi-class and binary classification problems and thereafter compare the results.
Four classifiers are used on these classification problems, namely k-Nearest Neighbor, Support
Vector Machine, Random Forest and Logistic regression. The Random Forest classifier is the best
performing classifier (0.521) of the multi-class classification task and the k Nearest Neighbor
classifier (0.702) for the binary classification task. Furthermore, this study examined to what extent
feature importance affects the models. Most of the models were rarely affected by the removal of
features and still managed to perform well. </p></li>
      
      <li>Jorina Scherff (Fall 2019) <a href="F2019_Jorina_Scherff_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> Due to the expanding number of mobile phone applications, consumers have a complex decision process
of which app to use. By making predictions of which application someone will use next based on past
behavior, a lot of research has tried to make automated recommendations that help the user simplify the
process. However, app owners can use such prediction models as well, by deciding when they can send
an advertisement banner for their app. Instead of predicting the next app as accurately as possible by
using as much information as possible, this model will predict the next app category by using only data
that is accessible for companies. This has, to our knowledge, not been investigated earlier, so the
research question of this thesis was as follows: To what extent can the phone application category that
someone will open be predicted, while using only mobile phone data that is accessible for companies?
A dataset is used containing mobile phone usage data with categories assigned to the apps. Different
classification models are compared and our findings demonstrate that Support Vector Machine worked
best with the features previous app opened, notification, hour of day, and duration of previous app.
However, there was a large difference in the recall values of the different categories, mostly caused by
the difference in the amount of presence in the dataset. Therefore, it depends on the popularity of the
app category how useful this model is. </p></li>
      
      <li>Olga Vieru (Fall 2019) <a href="F2019_Olga_Vieru_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> This research aims to explore whether we can predict and recommend information most relevant
to individual users, based on similar users in the same demographic category. Existing userbased collaborative filtering algorithms are applied, 
        in order to produce personalized content
recommendations based on group navigation patterns (page clicks). As a result, memory-based
(neighborhood) approaches and model-based (matrix factorization) techniques are tested out to
compare performance and results. The final dataset used for modelling is encoded in a 25x45 useritem feedback rating matrix. Among several algorithms 
        that are tried out, our tuned singular
value decomposition (SVD) model has the best performance and accuracy with RMSE=0.24,
MAE=0.16, compared to a chance-level performance of RMSE=1.14, MAE=0.80. Generated
output includes ten most relevant URLs per user group, as well as five new predicted links,
that users might find interesting. Several domain specific findings are discussed further on in
this report. Moreover, an approach measuring user-item predicted interest is presented, in order
to quantify each user group’s preference for a URL, based on the deviation from their overall
mean rating. In conclusion, this thesis contributes a low-resource data collection method with
Google Analytics, which could be used to inform decision-making in both commercial and noncommercial settings, and translated to other domains.</p></li>
      
      <li>Sophie Vink (Fall 2019) <a href="">pdf</a>
      <p><em>Abstract:</em> </p></li>
      
      <li>Aaron Wijnker (Fall 2019) <a href="F2019_Aaron_Wijnker_thesis.pdf">pdf</a>
      <p><em>Abstract:</em> Stress levels seem to have risen the past years. More people are claim
to feel longer periods of stress. This can have negative health effects.
Prediction of stress is important for stress detection, treatment and the
prevention of chronic stress. Phone use has also increased worldwide.
Phones play a big role in our everyday lives, which has led researchers
to believe patterns in phone usage could identify people’s emotions and
personality. The present study uses these phone usage patterns to predict
stress. Different models have already been built to obtain information from
phone usage data, focusing on app frequency. Previous research suggested
that the order of used apps could present additional information for stress
prediction. The results of the present study showed that, while both
non-sequential frequency and sequential patterns are able to predict stress
better than the majority baseline, the non-sequential patterns were more
useful for stress prediction. This suggests that sequential patterns might
not provide additional information for stress prediction. The results also
provide a new exciting stress prediction method, which could be combined
with existing methods.
</p></li>
      
      <li>Catherine Schwitzer (Fall 2018) <a href="F2018_Catherine_Schweitzer_Thesis.pdf">pdf</a>
      <p><em>Abstract:</em> The goal of this research was to determine if clustering mobile phone data can be used to
segment users into groups based on their behavior. Previous studies have attempted to profile
users according to mobile phone behavior, but they pre-determined the qualities of the
profiles manually as opposed to clustering. Studies that did utilize clustering for mobile
phone analysis primarily focused on predicting the next app users would open. This research
uses logging data from the MobileDNA app from Ghent University to create standard phone
behavior features, as well as new ones that quantify notification response time. Principal
component analysis was conducted on the feature set before clustering using DBSCAN. The
clustering results assigned most users into one main clusters, which suggests that clustering
may not be the most appropriate method for user profiling and that users are better considered
with regard to a spectrum of behavior. Additionally, it found notification response time is an
important feature in differentiating users and should be included in future studies.</p></li>
      
      <li>Eefje de Louw (Fall 2018) <a href="Eefje_de_Louw_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This research examines the effect of Conversational Human Voice on User Experience in chatbots in the context
of survey research performed by the municipality of ’s-Hertogenbosch (The Netherlands). Literature of suggests
that Conversational Human Voice has a positive effect on User Experience, but that never has been tested.
Therefore, this study proposes the following first research question: What is the effect of Conversational Human
Voice on the User Experience? In the research of Human-Computer Interaction, it is known that humans are
likely to attribute human characteristics to the computer when they interact with them and show similarities to
Human-Human interaction. It is said that people tend to adapt their language use to that of their conversational
agent. Therefore, this study proposes the second research question: To what extent do users alter their language
use to the addition of elements of Conversational Human Voice of the chatbot? The results of 551 participants
were analysed and the following conclusions are drawn: Conversational Human Voice does not necessarily lead
to a higher User Experience score in the context of survey research. For the context of survey research, one can
rather stick to the functional communication styles. Compared to the other Conversational Human Voice
categories, inviting rhetoric seems most suitable in the context of survey research. Significant differences were
found for the “helpfulness” and “clearness” of the chatbots. All in all, chatbots do show potential, but mainly in
more bound contexts such as answering frequently asked questions or managing appointment.</p></li>
      
      <li>Ronny Brouwers (Fall 2017) <a href="Ronny_Brouwers_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This thesis project used experimental, cross-situational, word-learning data, and the correct combination
of pseudo words and novel objects had to be identified in an ambiguous setting.
The first research question of this project aimed to identify which individual features could be used to
predict whether subjects would learn a word pair correctly in the testing phase. Based on the literature,
five potential features were identified and tested using a logistic regression and random forest algorithm.
The results showed that the more frequently a word-object
pair was presented without uncertainty, the more likely the pair was to be learned correctly.
The second research question focused on identifying different types of learners, as the literature showed
that different subjects may learn differently.
A Gaussian mixture model and hierarchical clustering were used, and clustering
analysis showed that the identified clusters were poorly separated and contained much noise.</p></li>
      
      <li>Yashi Thakkar (Spring 2017) <a href="Yashi_Thakkar_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This thesis aims at predicting an image based on different texts describing that image and question asked
while guessing the image.
The main research question is to evaluate the self-sufficiency of text data to identify a portrait with the help of text mining and similarity measures.
We used two types of vector space model combined with two types of decision rules and one similarity measure that is cosine similarity.
In our research, term frequency and inverse document frequency performed the best with a precision of 49%.
This shows how text itself can help reduce number of alternatives at the time of decision making. This
seems very useful in the area where tasks related to finding suspects are concerned.
Moreover, retaining few parts of speech can be helpful to increase the speed of mining as they retain a lot
of information simultaneously reducing the noise. </p></li>
      
      <li>Zeynep Oncu (Fall 2018) <a href="F2018_Zeynep_Oncu_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This study is a comparative analysis of supervised learning tasks using categorical texts and free-text
questions about facial details of people. The datasets used for this research were collected through online
experiments. This study used pre-trained word representations, which are known to be perform better than
the traditional text mining approaches. Categorical texts and word embeddings of question texts were
used as features in classification algorithms and their performances were evaluated with accuracy rates in
predicting answers to the questions. In other words, the research question was formed as “Which pretrained word embedding and classification models perform best in terms of accuracy rate in predicting
answers to yes/no questions?”
The findings showed that use of pre-trained word embedding models indeed led to better predictive
performances in some classification algorithms compared to the baseline for this dataset. </p></li>
      
      <li>Maarten Jansen <a href="Maarten_Jansen_Thesis.pdf">pdf</a>
        <p><em>Abstract:</em> This work investigates culture and cultural influence of visual narrative structures in
comic books, using a machine learning approach. It is motivated by proof that comics
are susceptible to adjustments stimulated by culture, and the scarcity of a machine
learning approach in studies on comics. Our main contribution is a better
understanding concerning cross-cultural differences in visual language, and evolvement
over time from a novel perspective. We find this contribution by asking the following
research question: To what extent can we predict continent, country, and decade of
publication based on narrative patterns in comic books published in the last eight
decades? The answer to this question is obtained by training a decision tree and naive
Bayes classifier, using narrative patterns extracted from the Visual Language Research
Corpus. The results demonstrate that there are cultural distinctions in patterns if we
examine continent or country of publication. However, if we examine decade of
publication we witness fewer characteristics pointing towards changes over time, unless
the time period investigated is of sufficient length, for example 50 years.</p></li>
    </ul>

  </body>
</html>
